{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_2_Student.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xR4A9aGPpiuZ","colab_type":"text"},"source":["#Student Name: \n","#ECE 595 Machine Learning II\n","#Project 2: Autoencoders - Student Code"]},{"cell_type":"code","metadata":{"id":"viCY7Zn5psMN","colab_type":"code","colab":{}},"source":["#Import necessary packages\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D\n","from keras.models import Sequential\n","import matplotlib.pyplot as plt\n","from keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2vATVUR9pxNT","colab_type":"text"},"source":["#Part 0: Importing and Normalizing Data"]},{"cell_type":"code","metadata":{"id":"nN1cUmn1p0vn","colab_type":"code","colab":{}},"source":["#Load MNIST data and normalize to [0,1]\n","(data_train, _), (data_test, _) = mnist.load_data()\n","data_train = data_train/255.0\n","data_test = data_test/255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"beNpVSplNsaJ","colab_type":"text"},"source":["#Part 1: Deep Fully-Connected AutoEncoder"]},{"cell_type":"markdown","metadata":{"id":"rfm3fYwcOyBk","colab_type":"text"},"source":["Answer the following questions: \n","\n","\n","1.  We want to predict output values of the intensity of the pixels which are between 0 to 1. Therefore choice of output layer activation function is important. (Open ended reasoning question). (a) Choose 'softmax’ or ‘sigmoid’. Reason why one is preferred over the other.\n"," \n","\n","2.   remove later \n","\n","  ANS: When"]},{"cell_type":"code","metadata":{"id":"vqYvEhZHN_h4","colab_type":"code","colab":{}},"source":["#Reshape training and testing data into 784-dimensional vectors\n","#FILL IN THIS CODE BLOCK"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEwdV09ms_KF","colab_type":"code","colab":{}},"source":["#Create autoencoder architecture\n","def deep_ae():\n","    model = Sequential()\n","\n","    #FILL THIS IN WITH MODEL ARCHITECTURE\n","\n","    return model\n","\n","#Create deep autoencoder graph\n","deep_ae = deep_ae()\n","\n","#Compile model using an appropriate loss and optimizer algorithm\n","#FILL THIS IN\n","\n","#Train the model and assign training meta-data to a variable\n","#FILL THIS IN\n","\n","#Calculate the reconstructions of the testing set (output of autoencoder on test set)\n","#FILL THIS IN\n","\n","\n","#Obtain encoder representation of data\n","get_hl = K.function([deep_ae.layers[0].input], [deep_ae.layers[2].output]) #The third hidden layer is indexed at 2\n","deep_ae_hl = get_hl([data_test_reshape_fcae])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cb1psOUHtZpk","colab_type":"code","colab":{}},"source":["#Plot loss vs epoch for BCE and MSE [Together or separate, Both accepted]\n","#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21ALTu2Vte2-","colab_type":"code","colab":{}},"source":["#Show samples of 10 images, their hidden layer representations, and their reconstructions\n","#FILL THIS CODE BLOCK IN AND PRODUCE SAMPLES"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tx3piQQZReeW","colab_type":"text"},"source":["Answer the following questions: \n","\n","\n","1.  Question 2c: BONUS [reasoning question]: Pair the output layer activation and loss function which performs better together. Linear, sigmoid, Binary cross entropy and Mean Square error\n"," \n","\n","2.  Question 5: Which loss function is better and why?\n","\n","3.  Question 6: If we were to predict pixels values [0 to 255] directly at the output of last layer. Should there be an activation function in last later?  If yes, which activation function and why?,  If No, reason why?"]},{"cell_type":"markdown","metadata":{"id":"TA4O3FwRt-sO","colab_type":"text"},"source":["#Part 2: Deep Convolutional AutoEncoder"]},{"cell_type":"code","metadata":{"id":"-a7Xlz7VuBl8","colab_type":"code","colab":{}},"source":["#Reshape data into 2-D signals and account for grayscale channel in each image\n","#FILL IN THIS CODE BLOCK"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-wENWWnuQGa","colab_type":"code","colab":{}},"source":["#Create Convolutional AutoEncoder Architecture\n","def cae():\n","    model = Sequential()\n","\n","    #FILL THIS IN WITH MODEL ARCHITECTURE\n","\n","    return model\n","\n","#Create deep autoencoder graph\n","conv_ae = cae()\n","\n","#Compile model using an appropriate loss and optimizer algorithm\n","#FILL THIS IN\n","\n","#Train the model and assign training meta-data to a variable\n","#FILL THIS IN\n","\n","#Calculate the reconstructions of the testing set (output of autoencoder on test set)\n","#FILL THIS IN\n","\n","\n","#Obtain encoder representation of data\n","get_hl = K.function([conv_ae.layers[0].input], [conv_ae.layers[3].output])  # The fourth hidden layer are indexed at 3\n","conv_ae_hl = get_hl([data_test_reshape_cae])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sVJO4y1ujCZ","colab_type":"code","colab":{}},"source":["#Plot loss vs epoch  for BCE and MSE [Together or separate, Both accepted]\n","#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcclERBAu0-u","colab_type":"code","colab":{}},"source":["#Show samples of 10 images, their hidden layer representations, and their reconstructions\n","#FILL THIS CODE BLOCK IN AND PRODUCE SAMPLES"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V8lacfJnUyET","colab_type":"text"},"source":["Answer the following questions: \n","\n","\n","1.  Question 4: Which loss function is better and why?"]},{"cell_type":"markdown","metadata":{"id":"6QfcpOPXvezs","colab_type":"text"},"source":["#Part 3: Denoising AutoEncoder"]},{"cell_type":"code","metadata":{"id":"c-lVJ3pfvhT5","colab_type":"code","colab":{}},"source":["#Inject noise into testing data\n","noise_factor = 0.25\n","data_train_noisy = data_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_train.shape)\n","data_test_noisy = data_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_test.shape)\n","\n","#Clip to stay within valid (normalized) pixel range\n","data_train_noisy = np.clip(data_train_noisy, 0., 1.)\n","data_test_noisy = np.clip(data_test_noisy, 0., 1.)\n","\n","#Reshape data to comply with input of denoising autoencoder\n","#FILL THIS IN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4zyjNfawzpU","colab_type":"code","colab":{}},"source":["#Show samples of 10 original images and their corrsponding noisy counterparts from the training set\n","#FILL THIS CODE BLOCK IN AND PRODUCE SAMPLES"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nuk3UxSxD9D","colab_type":"code","colab":{}},"source":["#Create denoising autoencoder architecture\n","def dae():\n","\n","    #FILL THIS IN WITH MODEL ARCHITECTURE\n","\n","    return model\n","  \n","\n","  \n","#Compile and train the DAE\n","#FILL THIS IN\n","\n","\n","#Generate denoised versions of noisy inputs\n","#FILL THIS IN\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_azeum1yxYIf","colab_type":"code","colab":{}},"source":["#Plot loss vs epoch\n","#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6-Xh7EDx0Vq","colab_type":"code","colab":{}},"source":["#Show samples of 10 original images, their noisy counterparts, and their de-noised images from the testing set\n","#FILL THIS CODE BLOCK IN AND PRODUCE SAMPLES"],"execution_count":null,"outputs":[]}]}