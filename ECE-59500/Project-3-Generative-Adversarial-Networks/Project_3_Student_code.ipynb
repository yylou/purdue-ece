{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_3_Student.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zKRfNs6ICuLD","colab_type":"text"},"source":["#Student Name: \n","#ECE 595 Machine Learning II\n","#Project 3: GAN - Student Code"]},{"cell_type":"code","metadata":{"id":"9nfXEi7WC0OA","colab_type":"code","colab":{}},"source":["#Import necessary packages\n","import numpy as np\n","import keras\n","from keras.layers import Dense, Dropout, Input\n","from keras.models import Model,Sequential\n","from keras.datasets import mnist\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.optimizers import adam\n","from keras.models import load_model\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fACNZwo4DBrP","colab_type":"text"},"source":["#Part 1: Implementing the GAN"]},{"cell_type":"code","metadata":{"id":"IAKtkDn6DQsy","colab_type":"code","colab":{}},"source":["#Load MNIST data and normalize to [-1, 1]\n","# Fill this in\n","\n","# The D-dimensional noise vector length\n","latent_dim = 100\n","\n","# Optimizer for discriminator, which will have a higher learning rate than adversarial model\n","def adam_optimizer():\n","    # FILL THIS IN\n","\n","# Genrerator model\n","def create_generator():\n","    # FILL THIS IN\n","\n","# Discriminator model\n","def create_discriminator():\n","    # FILL THIS IN\n","\n","# Create adversarial model\n","def create_gan(discriminator, generator):\n","    # FILL THIS IN\n","\n","# Creating GAN\n","generator = create_generator()\n","discriminator = create_discriminator()\n","gan = create_gan(discriminator, generator)\n","\n","# Model and training parameters\n","#ASSIGN VALUES TO THE FOLLOWING VARIABLES\n","epochs = \n","batch_size = \n","sample_interval = \n","\n","# Array to save training history\n","training_meta_data = np.zeros([epochs, 4])\n","\n","# Training the GAN\n","for e in range(1, epochs+1):\n","\n","    # Generate random noise as input\n","    # FILL THIS IN\n","\n","    # Generate fake MNIST images from generated noise\n","    # FILL THIS IN\n","\n","    # Get a random set of real MNIST images\n","    # FILL THIS IN\n","\n","    # Concatenate real and fake images into a single array (or batch)\n","    # FILL THIS IN\n","\n","    # Assign training labels (assign high probability, but not 1, to real images)\n","    # FILL THIS IN\n","\n","    # Allow discriminator parameters to be updated\n","    # FILL THIS IN\n","\n","    # Train discriminator on batch of real and fake images. Assign loss and accuracy to variable\n","    # FILL THIS IN\n","\n","    # Train adversarial model and try to fool discriminator (with incorrect label) \n","    # by generating a new batch of noise and assign them labels of real data\n","    # FILL THIS IN\n","\n","    # Keep discriminator weights constant while training generator\n","    # FILL THIS IN\n","\n","    # Train GAN (without updating discriminator weights) on new batch of fake images. Assign loss and accuracy to variable\n","    # FILL THIS IN\n","\n","    # Save training status\n","    # Discriminator and model loss\n","    training_meta_data[e-1, 0] = d_loss[0]\n","    training_meta_data[e-1, 1] = gan_loss[0]\n","\n","    # Discriminator and model accuracy\n","    training_meta_data[e-1, 2] = d_loss[1]\n","    training_meta_data[e-1, 3] = gan_loss[1]\n","\n","\n","    # If at sample interval, print training status and save samples\n","    if e % sample_interval == 0:\n","      \n","        # Print training status\n","        print(\"Epoch %d\" %e)\n","        log_mesg = \"%d: [Discriminaotr loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n","        log_mesg = \"%s  [GAN loss: %f, acc: %f]\" % (log_mesg, gan_loss[0], gan_loss[1])\n","        print(log_mesg)\n","        \n","        # Plot images \n","        r, c = 5, 5\n","\n","        # Create images from the noise (predict the outcome of the noise)\n","        gen_imgs = generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow((gen_imgs[cnt].reshape(28, 28)), cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqRJEDeIG9mx","colab_type":"code","colab":{}},"source":["# Plot model loss vs epoch\n","#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUJwhntuHJK8","colab_type":"code","colab":{}},"source":["# Plot accuracy vs epoch\n","#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dC_kPLFKHS7c","colab_type":"text"},"source":["[4]. Compare and comment on the results of GAN with dropout and without dropout.\n","\n","\n","[5][a]. Comment on importance of hyper-parameter tuning\n","\n","\n","[6]. Answer the following questions:\n","\n","\n","\n","1.   Why does the accuracy of the discriminator remain around 50%? Is this a good trait of the GAN? \n","\n","  ANS: \n","\n","\n","2.   How could this model be modified to produce cleaner (less noisy) images? \n","\n","  ANS: "]},{"cell_type":"markdown","metadata":{"id":"4ZBFSk1RHX5J","colab_type":"text"},"source":["#Part 2: Generating samples using trained generator"]},{"cell_type":"code","metadata":{"id":"LHaVnENuHcKQ","colab_type":"code","colab":{}},"source":["# Generate ten images from Gaussian noise using the trained generator from Part 1\n","# FILL THIS IN\n","\n","# Re-scale generated images to lie in [0, 1]\n","# FILL THIS IN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nak-dm-CIC6r","colab_type":"code","colab":{}},"source":["# Visualize generated noise\n","r, c = 2, 5\n","fig, axs = plt.subplots(r, c)\n","cnt = 0\n","for i in range(r):\n","    for j in range(c):\n","        axs[i,j].imshow((noise[cnt].reshape(10, 10)), cmap='gray')\n","        axs[i,j].axis('off')\n","        cnt += 1\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-Jir5ULIITP","colab_type":"code","colab":{}},"source":["# Visualize generated samples\n","r, c = 2, 5\n","fig, axs = plt.subplots(r, c)\n","cnt = 0\n","for i in range(r):\n","    for j in range(c):\n","        axs[i,j].imshow((generated_images[cnt].reshape(28, 28)), cmap='gray')\n","        axs[i,j].axis('off')\n","        cnt += 1\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4I4Q8fhIheQ","colab_type":"text"},"source":["#Part 3: Testing accuracy of generated images on ten samples"]},{"cell_type":"code","metadata":{"id":"pHjnlh6dIiMv","colab_type":"code","colab":{}},"source":["# Load mnist classifier and generated images\n","mnist_classifier = load_model('mnist_classifier.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_BFS0cgInWF","colab_type":"code","colab":{}},"source":["# ASSIGN CLASSES\n","labels = []\n","\n","# Convert integer labels to one-hot labels \n","labels = keras.utils.np_utils.to_categorical(labels, num_classes=10)\n","\n","# Show classifications\n","# FILL THIS IN \n","\n","# Evaluate accuracy\n","# FILL THIS IN "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxCLMvJnI95c","colab_type":"text"},"source":[""]}]}